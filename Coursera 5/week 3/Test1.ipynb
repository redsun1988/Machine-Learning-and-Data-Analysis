{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KONYAYEV.MAKSIM\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"SMSSpamCollection.txt\", sep=\"\t\", header=-1, names=[\"marker\", \"text\"])\n",
    "labels = np.where(data.marker == \"spam\", 1 , 0)\n",
    "texts = data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_classifier(vectorizer, transformer, classifier):\n",
    "    return Pipeline(\n",
    "            [(\"vectorizer\", vectorizer),\n",
    "            (\"transformer\", transformer),\n",
    "            (\"classifier\", classifier)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87851004553433965"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = LogisticRegression(random_state=2);\n",
    "cross_val_score(text_classifier(CountVectorizer(), TfidfTransformer(), lg), texts, labels, cv=10, scoring=\"f1\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer(fileName, value):\n",
    "    with open(fileName+\".txt\", \"w\") as fout:\n",
    "        fout.write(str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_answer(\"task5.txt\", \"0.9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lg = LogisticRegression(random_state=2);\n",
    "cv = CountVectorizer()    \n",
    "pipeline = Pipeline([(\"vectorizer\", cv),(\"classifier\", lg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "    ...nalty='l2', random_state=2, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(texts, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "forCheck = [\"FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB\",\n",
    "\"FreeMsg: Txt: claim your reward of 3 hours talk time\",\n",
    "\"Have you visited the last lecture on physics?\",\n",
    "\"Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$\",\n",
    "\"Only 99$\"]\n",
    "answer = pipeline.predict(forCheck)\n",
    "print answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_answer(\"task6.txt\", \"1 1 0 0 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.777625441986\n",
      "0.666587486877\n",
      "0.910667894248\n"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression();\n",
    "ranges = [(2,2), (3,3), (1,3)]\n",
    "for ng_range in ranges:\n",
    "    print cross_val_score(Pipeline([(\"vectorizer\", CountVectorizer(ngram_range=ng_range)),(\"classifier\", lg)]), \n",
    "                                texts, labels, scoring=\"f1\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_answer(\"task7.txt\", \"0.78 0.67 0.91\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.645501517799\n",
      "0.378719485246\n",
      "0.888485965606\n"
     ]
    }
   ],
   "source": [
    "#cvect = CountVectorizer(ngram_range = (2,2))\n",
    "#df_vect = cvect.fit_transform(df_sms.sms)\n",
    "#cross_val_score(MultinomialNB(), df_vect, df_sms['target'], cv = 10, scoring = 'f1').mean()\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB();\n",
    "ranges = [(2,2), (3,3), (1,3)]\n",
    "for ng_range in ranges:\n",
    "    cv = CountVectorizer(ngram_range=ng_range)\n",
    "    X = cv.fit_transform(texts)\n",
    "    print cross_val_score(nb, X, labels, cv=10, scoring=\"f1\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_answer(\"task8.txt\", \"0.66 0.38 0.89\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.866600422941\n"
     ]
    }
   ],
   "source": [
    "print cross_val_score(Pipeline([(\"vectorizer\", CountVectorizer(ngram_range=(1,1))),\n",
    "                                    (\"transformer\", TfidfTransformer()),\n",
    "                                    (\"classifier\", lg)]), \n",
    "                                texts, labels, scoring=\"f1\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011909622593339608"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.87851004553433965 - 0.866600422941"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_answer(\"task9.txt\", \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
