{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KONYAYEV.MAKSIM\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "import pandas\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Скачка тулкита\n",
    "#nltk.download()\n",
    "#Позитивные и негативные ID\n",
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Текст негативных отзывов\n",
    "negfeats = [movie_reviews.words(fileids=[f]) for f in negids]\n",
    "posfeats = [movie_reviews.words(fileids=[f]) for f in posids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1\n",
    "\n",
    "Создайте список из текстов всех имеющихся отзывов, а также список с классами, которые будет использовать ваш классификатор - 0 для негативных отзывов и 1 для позитивных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 24] Too many open files: u'C:\\\\Users\\\\KONYAYEV.MAKSIM\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\movie_reviews\\\\pos\\\\cv000_29590.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-943282b9635f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mallfeats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mposfeats\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnegfeats\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mallfeats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mallfeats\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposfeats\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnegfeats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\KONYAYEV.MAKSIM\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\nltk\\corpus\\reader\\util.pyc\u001b[0m in \u001b[0;36m__len__\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\KONYAYEV.MAKSIM\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\nltk\\corpus\\reader\\util.pyc\u001b[0m in \u001b[0;36miterate_from\u001b[1;34m(self, start_tok)\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\KONYAYEV.MAKSIM\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\nltk\\corpus\\reader\\util.pyc\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\KONYAYEV.MAKSIM\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\nltk\\data.pyc\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, encoding)\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 24] Too many open files: u'C:\\\\Users\\\\KONYAYEV.MAKSIM\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\movie_reviews\\\\pos\\\\cv000_29590.txt'"
     ]
    }
   ],
   "source": [
    "allfeats = posfeats + negfeats\n",
    "allfeats = [list(x) for x in allfeats]\n",
    "Y = [1] * len(posfeats) + [0] * len(negfeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2\n",
    "\n",
    "Подсчитайте количество отзывов в выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Количество отзывов в выборке  2000\n"
     ]
    }
   ],
   "source": [
    "print \"Количество отзывов в выборке \", len(posfeats) + len(negfeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3\n",
    "\n",
    "Подсчитайте долю класса 1 в выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля класса 1 -  0.5\n"
     ]
    }
   ],
   "source": [
    "print \"Доля класса 1 - \", len(posfeats) / float(len(allfeats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4\n",
    "\n",
    "Импортируйте CountVectorizer из sklearn.feature_extraction.text. Попробуйте использовать его с настройками по умолчанию для того, чтобы получить признаковое представление каждого текста. Скорее всего, попытка не увенчается успехом. Разберитесь, в чем причина, и добейтесь того, чтобы метод fit_transform у CountVectorizer успешно отрабатывал. Подсчитайте количество признаков в CountVectorizer. Никакой предварительной обработки текста (удаление стоп-слов, нормализация слов) на этом шаге делать не надо, в качестве признаков должны использоваться частоты слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "neg_pos_Docks = [u\" \".join(doc) for doc in allfeats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество признаков в новом пространстве =  39659\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(neg_pos_Docks)\n",
    "print \"Количество признаков в новом пространстве = \",len(vectorizer.get_feature_names())\n",
    "#vectorizer.transform([neg_pos_Docks[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5\n",
    "\n",
    "Соберите pipeline из CountVectorizer и LogisticRegression c настройками по-умолчанию и с помощью cross_val_score (также со стандартными настройками) оцените получаемое \"из коробки\" качество по accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_classifier(vectorizer, transformer ,classifier):\n",
    "    if (transformer is None) :\n",
    "        return Pipeline(\n",
    "                [(\"vectorizer\", vectorizer),\n",
    "                 (\"classifier\", classifier)]\n",
    "            )\n",
    "    else: \n",
    "        print \"transformer\"\n",
    "        return Pipeline(\n",
    "            [(\"vectorizer\", vectorizer),\n",
    "             (\"transformer\", transformer),\n",
    "             (\"classifier\", classifier)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83602165039290777"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = LogisticRegression()\n",
    "cross_val_score(text_classifier(CountVectorizer(), lg), neg_pos_Docks, Y, scoring = \"accuracy\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6\n",
    "\n",
    "Аналогично accuracy, оцените качество по ROC AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91078250580140141"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = LogisticRegression()\n",
    "cross_val_score(text_classifier(CountVectorizer(), lg), neg_pos_Docks, Y, scoring = \"roc_auc\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 7\n",
    "\n",
    "Обучите логистическую регрессию на всей доступной вам выборке и выведите 5 наиболее важных для модели признаков (подумайте, какие именно признаки стоит считать такими). Вам могут пригодиться метод get_feature_names() или поле vocabulary_ у класса CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lg = LogisticRegression()\n",
    "cv = CountVectorizer()\n",
    "classifier = text_classifier(cv, lg).fit(neg_pos_Docks, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'bad', u'unfortunately', u'worst', u'fun', u'waste']\n",
      "[-0.78225361709067653, -0.63662392955497649, -0.5928385327017055, 0.55605126142442174, -0.50819138655023299]\n"
     ]
    }
   ],
   "source": [
    "abs_coef = [abs(w) for w in lg.coef_[0]]\n",
    "indexes = sorted(range(len(abs_coef)), key=lambda i: abs_coef[i], reverse=True)[:5]\n",
    "print [ cv.get_feature_names()[index] for index in indexes]\n",
    "print [ lg.coef_[0][index] for index in indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer(fileName, value):\n",
    "    with open(fileName+\".txt\", \"w\") as fout:\n",
    "        fout.write(str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_answer(\"task1\", \"2000\")\n",
    "write_answer(\"task2\", \"0.5\")\n",
    "write_answer(\"task3\", \"39659\")\n",
    "write_answer(\"task4\", \"0.83602165039290777\")\n",
    "write_answer(\"task5\", \"0.91078250580140141\")\n",
    "write_answer(\"task6\", \"bad unfortunately\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WEEK 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1 \n",
    "\n",
    "Здесь и далее оценка качества будет выполняться с помощью cross_val_score с cv=5 и остальными параметрами по умолчанию. Оцените среднее качество ( .mean() ) и стандартное отклонение ( .std() ) по fold'ам для: а) pipeline из CountVectorizer() и LogisticRegression(), б) pipeline из TfidfVectorizer() и LogisticRegression(). В соответствующем пункте задания выпишите через пробел среднее в п. а, отклонение в п. а, среднее в п.б и отклонение в п. б"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Среднее -  0.841 Среднеквадратичное отклонение -  0.0167779617356\n"
     ]
    }
   ],
   "source": [
    "#а) pipeline из CountVectorizer() и LogisticRegression()\n",
    "lg = LogisticRegression()\n",
    "results = cross_val_score(text_classifier(CountVectorizer(), lg), neg_pos_Docks, Y, scoring = \"accuracy\", cv=5)\n",
    "print \"Среднее - \",results.mean(), \"Среднеквадратичное отклонение - \", results.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее -  0.821 Среднеквадратичное отклонение -  0.00406201920232\n"
     ]
    }
   ],
   "source": [
    "#б) pipeline из TfidfVectorizer() и LogisticRegression()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "lg = LogisticRegression()\n",
    "results = cross_val_score(text_classifier(TfidfVectorizer(), None,lg), neg_pos_Docks, Y, scoring = \"accuracy\", cv=5)\n",
    "print \"Среднее - \",results.mean(), \"Среднеквадратичное отклонение - \", results.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2\n",
    "\n",
    "Попробуйте задавать разные значения параметра min_df у CountVectorizer. Оцените качество вашего классификатора с min_df=10 и с min_df=50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее -  0.839 Среднеквадратичное отклонение -  0.0118953772534\n",
      "Среднее -  0.813 Среднеквадратичное отклонение -  0.0134536240471\n"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression()\n",
    "results = cross_val_score(text_classifier(CountVectorizer(min_df=10), None ,lg), neg_pos_Docks, Y, scoring = \"accuracy\", cv=5)\n",
    "print \"Среднее - \",np.mean(results), \"Среднеквадратичное отклонение - \", np.std(results)\n",
    "lg = LogisticRegression()\n",
    "results = cross_val_score(text_classifier(CountVectorizer(min_df=50), None ,lg), neg_pos_Docks, Y, scoring = \"accuracy\", cv=5)\n",
    "print \"Среднее - \",np.mean(results), \"Среднеквадратичное отклонение - \", np.std(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3\n",
    "\n",
    "Попробуйте использовать разные классификаторы после CountVectorizer. И vectorizer, и классификатор берите с параметрами по умолчанию. Сравните результаты для LogisticRegression, LinearSVC и SGDClassifier. Выпишите в ответе на соответствующий вопрос самое худшее качество из получившихся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее -  0.841 Среднеквадратичное отклонение -  0.0167779617356\n",
      "Среднее -  0.8325 Среднеквадратичное отклонение -  0.0162788205961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KONYAYEV.MAKSIM\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее -  0.7825 Среднеквадратичное отклонение -  0.042514703339\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "results = cross_val_score(text_classifier(CountVectorizer(), None ,classifier), neg_pos_Docks, Y, scoring = \"accuracy\", cv=5)\n",
    "print \"Среднее - \",np.mean(results), \"Среднеквадратичное отклонение - \", np.std(results)\n",
    "\n",
    "classifier = LinearSVC()\n",
    "results = cross_val_score(text_classifier(CountVectorizer(), None ,classifier), neg_pos_Docks, Y, scoring = \"accuracy\", cv=5)\n",
    "print \"Среднее - \",np.mean(results), \"Среднеквадратичное отклонение - \", np.std(results)\n",
    "\n",
    "classifier = SGDClassifier()\n",
    "results = cross_val_score(text_classifier(CountVectorizer(), None ,classifier), neg_pos_Docks, Y, scoring = \"accuracy\", cv=5)\n",
    "print \"Среднее - \",np.mean(results), \"Среднеквадратичное отклонение - \", np.std(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4\n",
    "\n",
    "Подготовьте список стоп-слов с помощью nltk.corpus.stopwords.words('english'), посмотрите на его элементы, и передайте его в соответствующий параметр CountVectorizer. В sklearn также предусмотрен свой список английских стоп-слов - для этого нужно задать соответствующий параметр равным строке 'english'. Оцените качество классификатора в одном и другом случае и выпишете сначала качество в первом варианте, затем во втором в соответствующем вопросе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nl_stopWords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее -  0.841 Среднеквадратичное отклонение -  0.0112472218792\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "results = cross_val_score(text_classifier(CountVectorizer(stop_words=nl_stopWords), None ,classifier), neg_pos_Docks, Y, scoring = \"accuracy\", cv=5)\n",
    "print \"Среднее - \",np.mean(results), \"Среднеквадратичное отклонение - \", np.std(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее -  0.839 Среднеквадратичное отклонение -  0.00982344135219\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "results = cross_val_score(text_classifier(CountVectorizer(stop_words=\"english\"), None ,classifier), neg_pos_Docks, Y, scoring = \"accuracy\", cv=5)\n",
    "print \"Среднее - \",np.mean(results), \"Среднеквадратичное отклонение - \", np.std(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5\n",
    "\n",
    "Попробуйте в CountVectorizer добавить к словам биграммы и измерить качество модели. А затем постройте модель на частотах буквенных n-грамм c n от 3 до 5, указав соответствующее значение параметра ngram_range и параметр analyzer='char_wb'. Полученные два числа запишите через пробел в ответе на соответствующий вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее -  0.8525 Среднеквадратичное отклонение -  0.0165075740192\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "results = cross_val_score(text_classifier(CountVectorizer(ngram_range=(1,2)), None ,classifier), neg_pos_Docks, Y, scoring = \"accuracy\", cv=5)\n",
    "print \"Среднее - \",np.mean(results), \"Среднеквадратичное отклонение - \", np.std(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее -  0.8205 Среднеквадратичное отклонение -  0.0100498756211\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "results = cross_val_score(text_classifier(CountVectorizer(ngram_range=(3,5), analyzer = \"char_wb\" ), None ,classifier), neg_pos_Docks, Y, scoring = \"accuracy\", cv=5)\n",
    "print \"Среднее - \",np.mean(results), \"Среднеквадратичное отклонение - \", np.std(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_answer(\"task1_w2\", \"0.841 0.0167779617356 0.821 0.00406201920232\")\n",
    "write_answer(\"task2_w2\", \"0.839 0.813\")\n",
    "write_answer(\"task3_w2\", \"0.7825\")\n",
    "write_answer(\"task4_w2\", \"0.841 0.839\")\n",
    "write_answer(\"task5_w2\", \"0.8525 0.8205\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
