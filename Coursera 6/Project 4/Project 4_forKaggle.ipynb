{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KONYAYEV.MAKSIM\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Импортируем библиотеки\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Функция создания каскада - пайплайна из ветроризатора, трансформатора и класификатора\n",
    "def text_classifier(vectorizer, transformer ,classifier):\n",
    "    if (transformer is None) :\n",
    "        return Pipeline(\n",
    "                [(\"vectorizer\", vectorizer),\n",
    "                 (\"classifier\", classifier)]\n",
    "            )\n",
    "    else: \n",
    "        return Pipeline(\n",
    "            [(\"vectorizer\", vectorizer),\n",
    "             (\"transformer\", transformer),\n",
    "             (\"classifier\", classifier)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.  ,  0.05,  0.1 ,  0.15])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Загрузка данных\n",
    "train_data = pd.read_csv('products_sentiment_train.tsv',delimiter='\\t',header=None)\n",
    "train_data.columns = ['X','y']\n",
    "X = train_data.X.values # (2000,)\n",
    "y = train_data.y.values # (2000,)\n",
    "test_data = pd.read_csv(\"products_sentiment_test.tsv\", sep=\"\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Подбор лучших параметров\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ngram_range = [(1,2),(1,3),(1,4),(2,3),(2,4),(3,5),(4,9),(5,9)]\n",
    "param_grid = {\n",
    "    \"vectorizer\": [TfidfVectorizer(), CountVectorizer()],\n",
    "    \"vectorizer__analyzer\": [\"word\", \"char\", \"char_wb\"],\n",
    "    \"vectorizer__ngram_range\": ngram_range,\n",
    "    \"vectorizer__stop_words\": [None, \"english\"],\n",
    "    \"classifier\": [LogisticRegression(), LinearSVC(), SGDClassifier()],\n",
    "    #\"vectorizer__max_df\": np.arange(0.9,1.0, 0.05),\n",
    "    #\"vectorizer__min_df\": np.arange(0.0,0.10, 0.05),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "    ...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'vectorizer__ngram_range': [(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 5), (4, 9), (5, 9)], 'classifier': [LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', rando...  strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipLine = text_classifier(CountVectorizer(), None ,LinearSVC())\n",
    "gridSearchCV = GridSearchCV(pipLine, param_grid=param_grid, n_jobs = -1)\n",
    "#Как взять все параметры модели\n",
    "#pipLine.get_params().keys()\n",
    "\n",
    "gridSearchCV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "      verbose=0),\n",
       " 'vectorizer': TfidfVectorizer(analyzer='char', binary=False, decode_error=u'strict',\n",
       "         dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(4, 9), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "         stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "         token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "         vocabulary=None),\n",
       " 'vectorizer__analyzer': 'char',\n",
       " 'vectorizer__ngram_range': (4, 9),\n",
       " 'vectorizer__stop_words': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79100000000000004"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchCV.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Использование лучших настроек\n",
    "pl = text_classifier(TfidfVectorizer(ngram_range=(4,9), analyzer='char'),None,LinearSVC())\n",
    "\n",
    "pl.fit(X, y)\n",
    "predict = pl.predict(test_data.text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Запись данных и сохранение в файл для кегла\n",
    "d = {'Id': range(0,500), \"y\" : predict}\n",
    "\n",
    "result = pd.DataFrame(data=d)\n",
    "result.to_csv(\"Project 4_forKaggle.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KONYAYEV.MAKSIM\\AppData\\Local\\Continuum\\anaconda2\n"
     ]
    }
   ],
   "source": [
    "#определение папки текущего откружения\n",
    "import sys\n",
    "print(sys.prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Сохранение данных в файл с помощью pickle\n",
    "pickle.dump(pl, open( \"defaultLinearSVC_ngramClassifier.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Загрузка данных\n",
    "#favorite_color = pickle.load( open( \"save.p\", \"rb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
